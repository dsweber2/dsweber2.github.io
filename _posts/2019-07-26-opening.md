---
layout: page
title:  "What's all this nonsense then?"
date:   2019-07-26 00:17:24 -0700
permalink: /opening/
categories:
  - rationality
  - meta
---

Principally, a place for me to scribble ideas, ideally in a way that is
accessible and useful to others. Generally, I'll talk about Effective Altruism
related topics, random bits of math and math puzzles, some data science
questions, possibly social science commentary from time to time.

Metacalculus

More intentionally, there's a project on summarizing mathematical theories deep
neural networks, best found via the [tag dnn theory](/tags/). Without further ado:

# Deep Neural networks: What do they know? Do they know stuff? Let's find out!
This is a broad subject which simultaneously has surprisingly old roots[^1] and
strikingly open questions. At the root of this is that the mathematical
structures of deep neural networks are so simple: stochastic gradient descent
(maybe with some memory), composition of *very* simple nonlinearities, and some
linear operators with some simple structures. This combination means
that there are parallels to be made with many fields of mathematics. Not all of
these end up telling us something useful, although knowing which is which is a
difficult question.

Roughly, you can expect this blog to give an opinionated and not always expert
take on many papers on the subject, presented in a fairly random fashion. There
are, however, summary pages that will give sub-abstract level summaries of the
works linking them together. Expect these pages (and this one) to change fairly
frequently.
* Approximation Theory
* Learning Theory
* Harmonic Analysis
* Combinatorial
* Tensor factorization
* (Stochastic) differential equations
* Matrix Analysis

One thing you can expect this blog to *not* do is try to teach you how to do
deep learning. There are a billion and one resources out there already. Just go
read distill if that's what you're interested in. (TODO: add a link to that
medium article)
## What was known: an insultingly brief tour

Most[^2] of the existing discussion before the current AI summer was focused on
approximation theory and learning theory. Broadly, approximation theory
approaches a class of functions, asks, <q>how well can you express this
function with these budget constraints?</q> and tends to call it a
day. Obviously that's not quite enough, since we need to *find* that function,
but it's certainly a minimal requirement for an effective function class, and
it allowed us to conclude that *at least* one hidden layer is necessary. There
are some interesting modern results that get into examining the trade-offs
between depth and width, which you can read more about
[here](blog/approximationTheory) (think of that as a meta post which will
update whenever I add a post in that series).

Learning theory, on the other hand, is concerned with making sure . Ideally,
these are the sorts of guarantees you want very broad theory to be able to give
you. One problem: these bounds are.

## Where do we go now?



[^1]: [Hilbert's thirteenth
    problem](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Arnold_representation_theorem)
    from the turn of the *18^th* century can actually be viewed as the sort
    of recursive nonlinearity that is at the heart of neural networks. As with
    many things, the link is more tenuous than you might like: it tells us that
    any multivariate function can actually be written as a two layer
    <q>network</q> where we get to choose the functions.

[^2]: there are other perspectives, such as the information geometry of neural
    networks that were floating around at the time, but they weren't the most
    prominent or the ones that got passed on.
